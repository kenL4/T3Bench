{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuqdRnkLuryu"
      },
      "source": [
        "# T3Bench for Enhancer Evaluation\n",
        "\n",
        "Please follow this notebook carefully to evaluate our enhancers for 3D generation.\n",
        "\n",
        "To run this locally, the following environment has been found to work well:\n",
        "\n",
        "- Python 3.10\n",
        "- Torch 2.3.0\n",
        "- CUDA 12.1\n",
        "- C++17 support\n",
        "\n",
        "#### Note: For a given run, save the video file from \"gsgen/checkpoints/{prompt}/{date}/{uid}/eval/video\" or save the GIF from Wandb and convert it to an MP4. This file will be needed for evaluation\n",
        "\n",
        "### For T3Bench, you will need a HuggingFace account and an OpenAI API account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPP_e_2_OTVI"
      },
      "source": [
        "# **Utilities [IMPORTANT]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvPXD97kSFVj"
      },
      "source": [
        "First we need to change the Colab Python version:\n",
        "\n",
        "1. Run the following cell\n",
        "2. Refresh the page\n",
        "3. Ensure python runtime is py310"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LA0fShwPNkCU"
      },
      "outputs": [],
      "source": [
        "!wget -O py310.sh https://raw.githubusercontent.com/j3soon/colab-python-version/main/scripts/py310.sh\n",
        "!bash py310.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If this has been done successfully, this should read something like:\n",
        "\n",
        "`User Current Version:- 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]`\n"
      ],
      "metadata": {
        "id": "KszNBRYClf_n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dRMVcjtNS-Bm"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(\"User Current Version:-\", sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQIjA3wdSLZl"
      },
      "source": [
        "Now run the following once to download the correct CUDA version and add to toolchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9DBf_RPORWa",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda_12.1.1_530.30.02_linux.run\n",
        "!sudo sh cuda_12.1.1_530.30.02_linux.run --silent --toolkit --no-opengl-libs\n",
        "import os\n",
        "\n",
        "os.environ[\"PATH\"] += \":/usr/local/cuda-12.1/bin\"\n",
        "os.environ[\"LD_LIBRARY_PATH\"] += \":/usr/local/cuda-12.1/lib64\"\n",
        "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda-12.1\"\n",
        "\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8oB87oKr9NS"
      },
      "source": [
        "# T3Bench Setup\n",
        "\n",
        "Now you will need to clone the T3Bench fork, or simply add the project to the colab file system in the path `/content/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpqHAuxbNvtl"
      },
      "outputs": [],
      "source": [
        "!rm -rf T3Bench/\n",
        "!git clone https://github.com/kenL4/T3Bench.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[IMPORTANT]**\n",
        "\n",
        "There is a known [issue](https://github.com/THU-LYJ-Lab/T3Bench/issues/6), where salesforce-lavis and imagereward have directly conflicting package requirements so they are incompatible. The workaround in my fork is to remove salesforce-lavis from the requirements and then install it directly afterwards with `--no-deps` enabled.\n",
        "\n",
        "Colab will throw a warning that you must restart the runtime but you can safely ignore this warning."
      ],
      "metadata": {
        "id": "VODiXyVpiZHy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T1jEyFJesp0B"
      },
      "outputs": [],
      "source": [
        "!pip install -r T3Bench/requirements.txt\n",
        "!pip install tokenizers --no-cache-dir\n",
        "!pip install fairscale==0.4.4 timm==0.4.12 salesforce-lavis --no-deps\n",
        "!pip install \"transformers<4.56\" sacremoses==0.1.0 \"tokenizers<0.22\" -U --no-deps --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare for evaluation"
      ],
      "metadata": {
        "id": "xIjOKYLngGBg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQdnY1ySt5cf"
      },
      "source": [
        "Only once you have followed these steps should you run the T3Bench scripts:\n",
        "1. First, you should replace the prompts in T3Bench/data/prompt_single.txt with the prompts you want to evaluate.\n",
        "2. Move the desired video file(s) to \"T3Bench/outputs_mesh_t3/gsgen_single/{prompt}/eval.mp4\"\n",
        "\n",
        "- If you need to convert GIF to MP4, you can use this shell command"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"T3Bench/outputs_video/gsgen_single/A_cactus_with_pink_flowers/\"\n",
        "!ffmpeg -i \"cactus.gif\" -movflags faststart -pix_fmt yuv420p \"T3Bench/outputs_video/gsgen_single/A_cactus_with_pink_flowers/eval.mp4\""
      ],
      "metadata": {
        "id": "0etSrCRWhGa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmmH-o-wtLX3"
      },
      "source": [
        "# Evaluate Quality\n",
        "\n",
        "Run the following cell to compute the quality metric of each prompt in \"T3Bench/data/prompt_single.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwnnpe__tKQZ"
      },
      "outputs": [],
      "source": [
        "# Quality specific versions\n",
        "!pip install \"numpy<2\" \"huggingface_hub==0.25.2\" diffusers transformers opencv-python clip -U\n",
        "\n",
        "!cd T3Bench/ && \\\n",
        "python run_eval_quality.py --group single --gpu 0 --method gsgen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT1umVQYtUrS"
      },
      "source": [
        "# Evaluate Alignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0Yb7QdCtag2"
      },
      "source": [
        "**[IMPORTANT]**\n",
        "\n",
        "From here on out, you will need an OpenAI API key, so **please replace the API key in run_caption.py and run_eval_alignment.py**\n",
        "\n",
        "Then, you can run the follwoing commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6b8c6rSteON"
      },
      "outputs": [],
      "source": [
        "# Alignment specific packages\n",
        "!pip install decord openai einops --upgrade\n",
        "!pip install \"transformers==4.30.2\" \"tokenizers<0.14\" -U --no-deps --no-cache-dir\n",
        "\n",
        "# For our limited VRAM, use a smaller model\n",
        "!sed -i 's/pretrain_flant5xxl/pretrain_flant5xl/g' \"T3Bench/run_caption.py\"\n",
        "\n",
        "!rm -rf outputs_caption\n",
        "!cd T3Bench/ && \\\n",
        "python3.10 run_caption.py --group single --gpu 0 --method gsgen\n",
        "!cd T3Bench/ && \\\n",
        "python run_eval_alignment.py --group single --gpu 0 --method gsgen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_A3-DIPbJg8"
      },
      "source": [
        "# T3Bench Utils\n",
        "If you want to clear the model cache, you can use this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2raGA9WNbI9C"
      },
      "outputs": [],
      "source": [
        "# Set to True or delete if clause to run\n",
        "if False:\n",
        "  import shutil\n",
        "  import os\n",
        "\n",
        "  cache_dirs = [\n",
        "      os.path.expanduser(\"/root/.cache/lavis\"),\n",
        "      os.path.expanduser(\"/root/.cache/huggingface/hub\"),\n",
        "      os.path.expanduser(\"/root/.cache/torch/hub/checkpoints\"),\n",
        "  ]\n",
        "\n",
        "  for d in cache_dirs:\n",
        "      if os.path.exists(d):\n",
        "          shutil.rmtree(d)\n",
        "          print(f\"Removed cache: {d}\")\n",
        "      else:\n",
        "          print(f\"Cache not found: {d}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py310",
      "name": "py310"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}